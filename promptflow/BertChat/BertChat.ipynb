{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chat with PDF - test, evaluation and experimentation\n",
    "\n",
    "We will walk you through how to use prompt flow Python SDK to test, evaluate and experiment with the \"Chat with PDF\" flow.\n",
    "\n",
    "## 0. Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install -r requirements.txt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Create connections\n",
    "Connection in prompt flow is for managing settings of your application behaviors incl. how to talk to different services (Azure OpenAI for example)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fpdoaoaice (AzureOpenAI)\n",
      "dataaioaicg (CognitiveSearch)\n",
      "chatpdf (Custom)\n",
      "aoai (AzureOpenAI)\n",
      "aoaicg (CognitiveSearch)\n",
      "entaoai (Custom)\n",
      "llmops (Custom)\n"
     ]
    }
   ],
   "source": [
    "import promptflow\n",
    "\n",
    "pf = promptflow.PFClient()\n",
    "\n",
    "# List all the available connections\n",
    "for c in pf.connections.list():\n",
    "    print(c.name + \" (\" + c.type + \")\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will need to have a connection named **YourNameBelow to run the chat_with_pdf flow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using existing connection\n",
      "name: fpdoaoaice\n",
      "module: promptflow.connections\n",
      "created_date: '2023-08-25T18:38:46.185205'\n",
      "last_modified_date: '2023-08-28T17:24:45.268116'\n",
      "type: azure_open_ai\n",
      "api_key: '******'\n",
      "api_base: https://dataaiapim.azure-api.net\n",
      "api_type: azure\n",
      "api_version: '2023-05-15'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create needed connection\n",
    "from promptflow.entities import AzureOpenAIConnection, OpenAIConnection\n",
    "\n",
    "try:\n",
    "    conn_name = \"fpdoaoaice\"\n",
    "    conn = pf.connections.get(name=conn_name)\n",
    "    print(\"using existing connection\")\n",
    "except:\n",
    "    # Follow https://learn.microsoft.com/en-us/azure/ai-services/openai/how-to/create-resource?pivots=web-portal to create an Azure Open AI resource.\n",
    "    connection = AzureOpenAIConnection(\n",
    "        name=conn_name,\n",
    "        api_key=\"<user-input>\",\n",
    "        api_base=\"<test_base>\",\n",
    "        api_type=\"azure\",\n",
    "        api_version=\"<test_version>\",\n",
    "    )\n",
    "\n",
    "    # use this if you have an existing OpenAI account\n",
    "    # connection = OpenAIConnection(\n",
    "    #     name=conn_name,\n",
    "    #     api_key=\"<user-input>\",\n",
    "    # )\n",
    "    conn = pf.connections.create_or_update(connection)\n",
    "    print(\"successfully created connection\")\n",
    "\n",
    "print(conn)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Test the flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-09-15 12:23:37 -0500   16700 execution          INFO     Start to run 6 nodes with concurrency level 16.\n",
      "2023-09-15 12:23:37 -0500   16700 execution.flow     INFO     Executing node setup_env. node run id: 758a0fbd-c2da-4cf8-b7dc-1c110c45140c_setup_env_0\n",
      "2023-09-15 12:23:37 -0500   16700 execution.flow     INFO     Node setup_env completes.\n",
      "2023-09-15 12:23:37 -0500   16700 execution.flow     INFO     Executing node download_tool. node run id: 758a0fbd-c2da-4cf8-b7dc-1c110c45140c_download_tool_0\n",
      "2023-09-15 12:23:37 -0500   16700 execution.flow     INFO     Executing node rewrite_question_tool. node run id: 758a0fbd-c2da-4cf8-b7dc-1c110c45140c_rewrite_question_tool_0\n",
      "2023-09-15 12:23:37 -0500   16700 execution.flow     INFO     [download_tool in line 0 (index starts from 0)] stdout> Pdf already exists in d:\\repos\\chatpdf\\Workshop\\promptflow\\BertChat\\.pdfs\\https___arxiv.org_pdf_1810.04805.pdf.pdf\n",
      "2023-09-15 12:23:37 -0500   16700 execution.flow     INFO     Node download_tool completes.\n",
      "2023-09-15 12:23:37 -0500   16700 execution.flow     INFO     Executing node build_index_tool. node run id: 758a0fbd-c2da-4cf8-b7dc-1c110c45140c_build_index_tool_0\n",
      "2023-09-15 12:23:37 -0500   16700 execution.flow     INFO     [build_index_tool in line 0 (index starts from 0)] stdout> Chunk size: 1024, chunk overlap: 64\n",
      "2023-09-15 12:23:37 -0500   16700 execution.flow     INFO     [build_index_tool in line 0 (index starts from 0)] stdout> Index path: d:\\repos\\chatpdf\\Workshop\\promptflow\\BertChat\\.index\\.pdfs\\https___arxiv.org_pdf_1810.04805.pdf.pdf.index_1024_64\n",
      "2023-09-15 12:23:37 -0500   16700 execution.flow     INFO     [build_index_tool in line 0 (index starts from 0)] stdout> Index already exists, bypassing index creation\n",
      "2023-09-15 12:23:37 -0500   16700 execution.flow     INFO     Node build_index_tool completes.\n",
      "2023-09-15 12:23:38 -0500   16700 execution.flow     INFO     [rewrite_question_tool in line 0 (index starts from 0)] stdout> Rewritten question: What does BERT stand for?\n",
      "2023-09-15 12:23:38 -0500   16700 execution.flow     INFO     Node rewrite_question_tool completes.\n",
      "2023-09-15 12:23:38 -0500   16700 execution.flow     INFO     Executing node find_context_tool. node run id: 758a0fbd-c2da-4cf8-b7dc-1c110c45140c_find_context_tool_0\n",
      "2023-09-15 12:23:39 -0500   16700 execution.flow     INFO     Node find_context_tool completes.\n",
      "2023-09-15 12:23:39 -0500   16700 execution.flow     INFO     Executing node qna_tool. node run id: 758a0fbd-c2da-4cf8-b7dc-1c110c45140c_qna_tool_0\n",
      "2023-09-15 12:23:39 -0500   16700 execution.flow     INFO     Node qna_tool completes.\n",
      "{'answer': 'BERT stands for Bidirectional Encoder Representations from Transformers.', 'context': ['BERT: Pre-training of Deep Bidirectional Transformers for\\nLanguage Understanding\\nJacob Devlin Ming-Wei Chang Kenton Lee Kristina Toutanova\\nGoogle AI Language\\nfjacobdevlin,mingweichang,kentonl,kristout g@google.com\\nAbstract\\nWe introduce a new language representa-\\ntion model called BERT , which stands for\\nBidirectional Encoder Representations from\\nTransformers. Unlike recent language repre-\\nsentation models (Peters et al., 2018a; Rad-\\nford et al., 2018), BERT is designed to pre-\\ntrain deep bidirectional representations from\\nunlabeled text by jointly conditioning on both\\nleft and right context in all layers. As a re-\\nsult, the pre-trained BERT model can be ﬁne-\\ntuned with just one additional output layer\\nto create state-of-the-art models for a wide\\nrange of tasks, such as question answering and\\nlanguage inference, without substantial task-\\nspeciﬁc architecture modiﬁcations.\\nBERT is conceptually simple and empirically\\npowerful. It obtains new state-of-the-art re-\\nsults on eleven natural language processing\\ntasks,', 'e 1 will serve\\nas a running example for this section.\\nA distinctive feature of BERT is its uniﬁed ar-\\nchitecture across different tasks. There is mini-mal difference between the pre-trained architec-\\nture and the ﬁnal downstream architecture.\\nModel Architecture BERT’s model architec-\\nture is a multi-layer bidirectional Transformer en-\\ncoder based on the original implementation de-\\nscribed in Vaswani et al. (2017) and released in\\nthetensor2tensor library.1Because the use\\nof Transformers has become common and our im-\\nplementation is almost identical to the original,\\nwe will omit an exhaustive background descrip-\\ntion of the model architecture and refer readers to\\nVaswani et al. (2017) as well as excellent guides\\nsuch as “The Annotated Transformer.”2\\nIn this work, we denote the number of layers\\n(i.e., Transformer blocks) as L, the hidden size as\\nH, and the number of self-attention heads as A.3\\nWe primarily report results on two model sizes:\\nBERT BASE (L=12, H=768, A=12, Total Param-\\neters=110M) and BERT LARGE (L', 'E (L=12, H=768, A=12, Total Param-\\neters=110M) and BERT LARGE (L=24, H=1024,\\nA=16, Total Parameters=340M).\\nBERT BASE was chosen to have the same model\\nsize as OpenAI GPT for comparison purposes.\\nCritically, however, the BERT Transformer uses\\nbidirectional self-attention, while the GPT Trans-\\nformer uses constrained self-attention where every\\ntoken can only attend to context to its left.4\\n1https://github.com/tensorﬂow/tensor2tensor\\n2http://nlp.seas.harvard.edu/2018/04/03/attention.html\\n3In all cases we set the feed-forward/ﬁlter size to be 4H,\\ni.e., 3072 for the H= 768 and 4096 for the H= 1024 .\\n4We note that in the literature the bidirectional Trans-Input/Output Representations To make BERT\\nhandle a variety of down-stream tasks, our input\\nrepresentation is able to unambiguously represent\\nboth a single sentence and a pair of sentences\\n(e.g.,hQuestion, Answeri) in one token sequence.\\nThroughout this work, a “sentence” can be an arbi-\\ntrary span of contiguous text, rather than an actual\\nlinguistic sentence. A “s', 'g BERT\\nFine-tuning is straightforward since the self-\\nattention mechanism in the Transformer al-\\nlows BERT to model many downstream tasks—\\nwhether they involve single text or text pairs—by\\nswapping out the appropriate inputs and outputs.\\nFor applications involving text pairs, a common\\npattern is to independently encode text pairs be-\\nfore applying bidirectional cross attention, such\\nas Parikh et al. (2016); Seo et al. (2017). BERT\\ninstead uses the self-attention mechanism to unify\\nthese two stages, as encoding a concatenated text\\npair with self-attention effectively includes bidi-\\nrectional cross attention between two sentences.\\nFor each task, we simply plug in the task-\\nspeciﬁc inputs and outputs into BERT and ﬁne-\\ntune all the parameters end-to-end. At the in-\\nput, sentence Aand sentence Bfrom pre-training\\nare analogous to (1) sentence pairs in paraphras-\\ning, (2) hypothesis-premise pairs in entailment, (3)\\nquestion-passage pairs in question answering, and(4) a degenerate text- ?pair in text classiﬁcation\\no', 'm one or more layers without ﬁne-tuning\\nany parameters of BERT. These contextual em-\\nbeddings are used as input to a randomly initial-\\nized two-layer 768-dimensional BiLSTM before\\nthe classiﬁcation layer.\\nResults are presented in Table 7. BERT LARGE\\nperforms competitively with state-of-the-art meth-\\nods. The best performing method concatenates the\\ntoken representations from the top four hidden lay-\\ners of the pre-trained Transformer, which is only\\n0.3 F1 behind ﬁne-tuning the entire model. This\\ndemonstrates that BERT is effective for both ﬁne-\\ntuning and feature-based approaches.\\n6 Conclusion\\nRecent empirical improvements due to transfer\\nlearning with language models have demonstrated\\nthat rich, unsupervised pre-training is an integral\\npart of many language understanding systems. In\\nparticular, these results enable even low-resource\\ntasks to beneﬁt from deep unidirectional architec-\\ntures. Our major contribution is further general-\\nizing these ﬁndings to deep bidirectional architec-\\ntures, allowing the same p']}\n"
     ]
    }
   ],
   "source": [
    "output = pf.flows.test(\n",
    "    \".\",\n",
    "    inputs={\n",
    "        \"chat_history\": [],\n",
    "        \"pdf_url\": \"https://arxiv.org/pdf/1810.04805.pdf\",\n",
    "        \"question\": \"what is BERT?\",\n",
    "    },\n",
    ")\n",
    "print(output)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Run the flow with a data file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-09-15 12:27:05 -0500   15492 execution          INFO     Start to run 6 nodes with concurrency level 2.\n",
      "2023-09-15 12:27:05 -0500   15492 execution.flow     INFO     Executing node setup_env. node run id: bertchat_default_20230915_122701_506440_setup_env_0\n",
      "2023-09-15 12:27:05 -0500   15492 execution.flow     INFO     Node setup_env completes.\n",
      "2023-09-15 12:27:05 -0500   15492 execution.flow     INFO     Executing node download_tool. node run id: bertchat_default_20230915_122701_506440_download_tool_0\n",
      "2023-09-15 12:27:05 -0500   15492 execution.flow     INFO     Executing node rewrite_question_tool. node run id: bertchat_default_20230915_122701_506440_rewrite_question_tool_0\n",
      "2023-09-15 12:27:05 -0500   15492 execution.flow     INFO     [download_tool in line 0 (index starts from 0)] stdout> Pdf already exists in d:\\repos\\chatpdf\\Workshop\\promptflow\\BertChat\\.pdfs\\https___arxiv.org_pdf_1810.04805.pdf.pdf\n",
      "2023-09-15 12:27:05 -0500   15492 execution.flow     INFO     Node download_tool completes.\n",
      "2023-09-15 12:27:05 -0500   15492 execution.flow     INFO     Executing node build_index_tool. node run id: bertchat_default_20230915_122701_506440_build_index_tool_0\n",
      "2023-09-15 12:27:05 -0500   15492 execution.flow     INFO     [build_index_tool in line 0 (index starts from 0)] stdout> Chunk size: 256, chunk overlap: 32\n",
      "2023-09-15 12:27:05 -0500   15492 execution.flow     INFO     [build_index_tool in line 0 (index starts from 0)] stdout> Index path: d:\\repos\\chatpdf\\Workshop\\promptflow\\BertChat\\.index\\.pdfs\\https___arxiv.org_pdf_1810.04805.pdf.pdf.index_256_32\n",
      "2023-09-15 12:27:05 -0500   15492 execution.flow     INFO     [build_index_tool in line 0 (index starts from 0)] stdout> Index already exists, bypassing index creation\n",
      "2023-09-15 12:27:05 -0500   15492 execution.flow     INFO     Node build_index_tool completes.\n",
      "2023-09-15 12:27:06 -0500   15492 execution.flow     INFO     [rewrite_question_tool in line 0 (index starts from 0)] stdout> Rewritten question: What is the name of the new language representation model introduced in the document?\n",
      "2023-09-15 12:27:06 -0500   15492 execution.flow     INFO     Node rewrite_question_tool completes.\n",
      "2023-09-15 12:27:06 -0500   15492 execution.flow     INFO     Executing node find_context_tool. node run id: bertchat_default_20230915_122701_506440_find_context_tool_0\n",
      "2023-09-15 12:27:07 -0500   15492 execution.flow     INFO     Node find_context_tool completes.\n",
      "2023-09-15 12:27:07 -0500   15492 execution.flow     INFO     Executing node qna_tool. node run id: bertchat_default_20230915_122701_506440_qna_tool_0\n",
      "2023-09-15 12:27:07 -0500   15492 execution.flow     INFO     Node qna_tool completes.\n",
      "2023-09-15 12:27:08 -0500   16700 execution          INFO     Process 0 queue empty, exit.\n",
      "======= Run Summary =======\n",
      "\n",
      "Run name: \"bertchat_default_20230915_122701_506440\"\n",
      "Run status: \"Completed\"\n",
      "Start time: \"2023-09-15 12:27:01.506440\"\n",
      "Duration: \"0:00:07.596862\"\n",
      "Output path: \"C:\\Users\\astalati\\.promptflow\\.runs\\bertchat_default_20230915_122701_506440\"\n",
      "\n",
      "name: bertchat_default_20230915_122701_506440\n",
      "created_on: '2023-09-15T12:27:01.506440'\n",
      "status: Completed\n",
      "display_name: bertchat_default_20230915_122701_506440\n",
      "description: null\n",
      "tags: null\n",
      "properties:\n",
      "  flow_path: D:/repos/chatpdf/Workshop/promptflow/BertChat\n",
      "  output_path: C:/Users/astalati/.promptflow/.runs/bertchat_default_20230915_122701_506440\n",
      "flow_name: BertChat\n",
      "data: D:/repos/chatpdf/Workshop/promptflow/BertChat/data/bert-paper-qna-1-line.jsonl\n",
      "output: C:/Users/astalati/.promptflow/.runs/bertchat_default_20230915_122701_506440/flow_outputs/output.jsonl\n",
      "\n"
     ]
    }
   ],
   "source": [
    "flow_path = \".\"\n",
    "data_path = \"./data/bert-paper-qna-1-line.jsonl\"\n",
    "\n",
    "config_2k_context = {\n",
    "    \"EMBEDDING_MODEL_DEPLOYMENT_NAME\": \"embedding\",\n",
    "    \"CHAT_MODEL_DEPLOYMENT_NAME\": \"chat\",\n",
    "    \"PROMPT_TOKEN_LIMIT\": 2000,\n",
    "    \"MAX_COMPLETION_TOKENS\": 256,\n",
    "    \"VERBOSE\": True,\n",
    "    \"CHUNK_SIZE\": 256,\n",
    "    \"CHUNK_OVERLAP\": 32,\n",
    "}\n",
    "\n",
    "column_mapping = {\n",
    "    \"question\": \"${data.question}\",\n",
    "    \"pdf_url\": \"${data.pdf_url}\",\n",
    "    \"chat_history\": \"${data.chat_history}\",\n",
    "    \"config\": config_2k_context,\n",
    "}\n",
    "run_2k_context = pf.run(flow=flow_path, data=data_path, column_mapping=column_mapping)\n",
    "pf.stream(run_2k_context)\n",
    "\n",
    "print(run_2k_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>inputs.chat_history</th>\n",
       "      <th>inputs.config</th>\n",
       "      <th>inputs.pdf_url</th>\n",
       "      <th>inputs.question</th>\n",
       "      <th>inputs.line_number</th>\n",
       "      <th>outputs.answer</th>\n",
       "      <th>outputs.context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[]</td>\n",
       "      <td>{'EMBEDDING_MODEL_DEPLOYMENT_NAME': 'embedding...</td>\n",
       "      <td>https://arxiv.org/pdf/1810.04805.pdf</td>\n",
       "      <td>What is the name of the new language represent...</td>\n",
       "      <td>0</td>\n",
       "      <td>The name of the new language representation mo...</td>\n",
       "      <td>[e introduce a new language representa-\\ntion ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  inputs.chat_history                                      inputs.config  \\\n",
       "0                  []  {'EMBEDDING_MODEL_DEPLOYMENT_NAME': 'embedding...   \n",
       "\n",
       "                         inputs.pdf_url  \\\n",
       "0  https://arxiv.org/pdf/1810.04805.pdf   \n",
       "\n",
       "                                     inputs.question  inputs.line_number  \\\n",
       "0  What is the name of the new language represent...                   0   \n",
       "\n",
       "                                      outputs.answer  \\\n",
       "0  The name of the new language representation mo...   \n",
       "\n",
       "                                     outputs.context  \n",
       "0  [e introduce a new language representa-\\ntion ...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pf.get_details(run_2k_context)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Evaluate the \"groundedness\"\n",
    "The [eval-groundedness flow](../../evaluation/eval-groundedness/) is using ChatGPT/GPT4 model to grade the answers generated by chat-with-pdf flow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-09-15 12:38:46 -0500   26892 execution          INFO     Start to run 2 nodes with concurrency level 2.\n",
      "2023-09-15 12:38:46 -0500   26892 execution.flow     INFO     Executing node gpt_groundedness. node run id: eval_groundness_default_20230915_123840_573750_gpt_groundedness_0\n",
      "2023-09-15 12:38:47 -0500   26892 execution.flow     INFO     Node gpt_groundedness completes.\n",
      "2023-09-15 12:38:47 -0500   26892 execution.flow     INFO     Executing node parse_score. node run id: eval_groundness_default_20230915_123840_573750_parse_score_0\n",
      "2023-09-15 12:38:47 -0500   26892 execution.flow     INFO     Node parse_score completes.\n",
      "2023-09-15 12:38:48 -0500   16700 execution          INFO     Process 0 queue empty, exit.\n",
      "2023-09-15 12:38:48 -0500   16700 execution          INFO     Executing aggregation nodes...\n",
      "2023-09-15 12:38:48 -0500   16700 execution          INFO     Start to run 1 nodes with concurrency level 2.\n",
      "2023-09-15 12:38:48 -0500   16700 execution.flow     INFO     Executing node aggregate. node run id: eval_groundness_default_20230915_123840_573750_aggregate_reduce\n",
      "2023-09-15 12:38:48 -0500   16700 execution.flow     INFO     Node aggregate completes.\n",
      "2023-09-15 12:38:48 -0500   16700 execution          INFO     Finish executing aggregation nodes.\n",
      "======= Run Summary =======\n",
      "\n",
      "Run name: \"eval_groundness_default_20230915_123840_573750\"\n",
      "Run status: \"Completed\"\n",
      "Start time: \"2023-09-15 12:38:40.571203\"\n",
      "Duration: \"0:00:07.649757\"\n",
      "Output path: \"C:\\Users\\astalati\\.promptflow\\.runs\\eval_groundness_default_20230915_123840_573750\"\n",
      "\n",
      "name: eval_groundness_default_20230915_123840_573750\n",
      "created_on: '2023-09-15T12:38:40.571203'\n",
      "status: Completed\n",
      "display_name: eval_groundedness_2k_context\n",
      "description: null\n",
      "tags: null\n",
      "properties:\n",
      "  flow_path: D:/repos/chatpdf/Workshop/promptflow/BertChat/eval-groundness\n",
      "  output_path: C:/Users/astalati/.promptflow/.runs/eval_groundness_default_20230915_123840_573750\n",
      "flow_name: eval-groundness\n",
      "data: null\n",
      "output: C:/Users/astalati/.promptflow/.runs/eval_groundness_default_20230915_123840_573750/flow_outputs/output.jsonl\n",
      "run: bertchat_default_20230915_122701_506440\n",
      "\n"
     ]
    }
   ],
   "source": [
    "eval_groundedness_flow_path = \"../EvalGroundness/\"\n",
    "eval_groundedness_2k_context = pf.run(\n",
    "    flow=eval_groundedness_flow_path,\n",
    "    run=run_2k_context,\n",
    "    column_mapping={\n",
    "        \"question\": \"${run.inputs.question}\",\n",
    "        \"answer\": \"${run.outputs.answer}\",\n",
    "        \"context\": \"${run.outputs.context}\",\n",
    "    },\n",
    "    display_name=\"eval_groundedness_2k_context\",\n",
    ")\n",
    "pf.stream(eval_groundedness_2k_context)\n",
    "\n",
    "print(eval_groundedness_2k_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>inputs.answer</th>\n",
       "      <th>inputs.context</th>\n",
       "      <th>inputs.question</th>\n",
       "      <th>inputs.line_number</th>\n",
       "      <th>outputs.groundedness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The name of the new language representation mo...</td>\n",
       "      <td>[e introduce a new language representa-\\ntion ...</td>\n",
       "      <td>What is the name of the new language represent...</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       inputs.answer  \\\n",
       "0  The name of the new language representation mo...   \n",
       "\n",
       "                                      inputs.context  \\\n",
       "0  [e introduce a new language representa-\\ntion ...   \n",
       "\n",
       "                                     inputs.question  inputs.line_number  \\\n",
       "0  What is the name of the new language represent...                   0   \n",
       "\n",
       "   outputs.groundedness  \n",
       "0                    10  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pf.get_details(eval_groundedness_2k_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'groundedness': 10.0}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pf.get_metrics(eval_groundedness_2k_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The HTML file is generated at 'C:\\\\Users\\\\astalati\\\\AppData\\\\Local\\\\Temp\\\\pf-visualize-detail-zjcjmjfx.html'.\n",
      "Trying to view the result in a web browser...\n",
      "Successfully visualized from the web browser.\n"
     ]
    }
   ],
   "source": [
    "pf.visualize(eval_groundedness_2k_context)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will see a web page like this. It gives you detail about how each row is graded and even the details how the evaluation run executes:\n",
    "![pf-visualize-screenshot](./assets/pf-visualize-screenshot.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Try a different configuration and evaluate again - experimentation\n",
    "\n",
    "NOTE: since we only use 3 lines of test data in this example, and because of the non-deterministic nature of LLMs, don't be surprised if you see exact same metrics when you run this process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-09-15 13:19:35 -0500    2712 execution          INFO     Start to run 6 nodes with concurrency level 2.\n",
      "2023-09-15 13:19:35 -0500    2712 execution.flow     INFO     Executing node setup_env. node run id: bertchat_default_20230915_131927_633984_setup_env_0\n",
      "2023-09-15 13:19:36 -0500    2712 execution.flow     INFO     Node setup_env completes.\n",
      "2023-09-15 13:19:36 -0500    2712 execution.flow     INFO     Executing node download_tool. node run id: bertchat_default_20230915_131927_633984_download_tool_0\n",
      "2023-09-15 13:19:36 -0500    2712 execution.flow     INFO     Executing node rewrite_question_tool. node run id: bertchat_default_20230915_131927_633984_rewrite_question_tool_0\n",
      "2023-09-15 13:19:36 -0500    2712 execution.flow     INFO     [download_tool in line 0 (index starts from 0)] stdout> Pdf already exists in d:\\repos\\chatpdf\\Workshop\\promptflow\\BertChat\\.pdfs\\https___arxiv.org_pdf_1810.04805.pdf.pdf\n",
      "2023-09-15 13:19:36 -0500    2712 execution.flow     INFO     Node download_tool completes.\n",
      "2023-09-15 13:19:36 -0500    2712 execution.flow     INFO     Executing node build_index_tool. node run id: bertchat_default_20230915_131927_633984_build_index_tool_0\n",
      "2023-09-15 13:19:36 -0500    2712 execution.flow     INFO     [build_index_tool in line 0 (index starts from 0)] stdout> Chunk size: 256, chunk overlap: 32\n",
      "2023-09-15 13:19:36 -0500    2712 execution.flow     INFO     [build_index_tool in line 0 (index starts from 0)] stdout> Index path: d:\\repos\\chatpdf\\Workshop\\promptflow\\BertChat\\.index\\.pdfs\\https___arxiv.org_pdf_1810.04805.pdf.pdf.index_256_32\n",
      "2023-09-15 13:19:36 -0500    2712 execution.flow     INFO     [build_index_tool in line 0 (index starts from 0)] stdout> Index already exists, bypassing index creation\n",
      "2023-09-15 13:19:36 -0500    2712 execution.flow     INFO     Node build_index_tool completes.\n",
      "2023-09-15 13:19:38 -0500    2712 execution.flow     INFO     [rewrite_question_tool in line 0 (index starts from 0)] stdout> Rewritten question: What is the name of the new language representation model introduced in the document?\n",
      "2023-09-15 13:19:38 -0500    2712 execution.flow     INFO     Node rewrite_question_tool completes.\n",
      "2023-09-15 13:19:38 -0500    2712 execution.flow     INFO     Executing node find_context_tool. node run id: bertchat_default_20230915_131927_633984_find_context_tool_0\n",
      "2023-09-15 13:19:39 -0500    2712 execution.flow     INFO     Node find_context_tool completes.\n",
      "2023-09-15 13:19:39 -0500    2712 execution.flow     INFO     Executing node qna_tool. node run id: bertchat_default_20230915_131927_633984_qna_tool_0\n",
      "2023-09-15 13:19:40 -0500    2712 execution.flow     INFO     Node qna_tool completes.\n",
      "2023-09-15 13:19:41 -0500   16700 execution          INFO     Process 0 queue empty, exit.\n",
      "======= Run Summary =======\n",
      "\n",
      "Run name: \"bertchat_default_20230915_131927_633984\"\n",
      "Run status: \"Completed\"\n",
      "Start time: \"2023-09-15 13:19:27.632447\"\n",
      "Duration: \"0:00:15.312801\"\n",
      "Output path: \"C:\\Users\\astalati\\.promptflow\\.runs\\bertchat_default_20230915_131927_633984\"\n",
      "\n",
      "name: bertchat_default_20230915_131927_633984\n",
      "created_on: '2023-09-15T13:19:27.632447'\n",
      "status: Completed\n",
      "display_name: bertchat_default_20230915_131927_633984\n",
      "description: null\n",
      "tags: null\n",
      "properties:\n",
      "  flow_path: D:/repos/chatpdf/Workshop/promptflow/BertChat\n",
      "  output_path: C:/Users/astalati/.promptflow/.runs/bertchat_default_20230915_131927_633984\n",
      "flow_name: BertChat\n",
      "data: D:/repos/chatpdf/Workshop/promptflow/BertChat/data/bert-paper-qna-1-line.jsonl\n",
      "output: C:/Users/astalati/.promptflow/.runs/bertchat_default_20230915_131927_633984/flow_outputs/output.jsonl\n",
      "\n"
     ]
    }
   ],
   "source": [
    "config_3k_context = {\n",
    "    \"EMBEDDING_MODEL_DEPLOYMENT_NAME\": \"embedding\",\n",
    "    \"CHAT_MODEL_DEPLOYMENT_NAME\": \"chat\",\n",
    "    \"PROMPT_TOKEN_LIMIT\": 3000,\n",
    "    \"MAX_COMPLETION_TOKENS\": 256,\n",
    "    \"VERBOSE\": True,\n",
    "    \"CHUNK_SIZE\": 256,\n",
    "    \"CHUNK_OVERLAP\": 32,\n",
    "}\n",
    "\n",
    "run_3k_context = pf.run(flow=flow_path, data=data_path, column_mapping=column_mapping)\n",
    "pf.stream(run_3k_context)\n",
    "\n",
    "print(run_3k_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-09-15 13:19:50 -0500   32024 execution          INFO     Start to run 2 nodes with concurrency level 2.\n",
      "2023-09-15 13:19:50 -0500   32024 execution.flow     INFO     Executing node gpt_groundedness. node run id: eval_groundness_default_20230915_131943_010944_gpt_groundedness_0\n",
      "2023-09-15 13:19:51 -0500   32024 execution.flow     INFO     Node gpt_groundedness completes.\n",
      "2023-09-15 13:19:51 -0500   32024 execution.flow     INFO     Executing node parse_score. node run id: eval_groundness_default_20230915_131943_010944_parse_score_0\n",
      "2023-09-15 13:19:51 -0500   32024 execution.flow     INFO     Node parse_score completes.\n",
      "2023-09-15 13:19:52 -0500   16700 execution          INFO     Process 0 queue empty, exit.\n",
      "2023-09-15 13:19:52 -0500   16700 execution          INFO     Executing aggregation nodes...\n",
      "2023-09-15 13:19:52 -0500   16700 execution          INFO     Start to run 1 nodes with concurrency level 2.\n",
      "2023-09-15 13:19:52 -0500   16700 execution.flow     INFO     Executing node aggregate. node run id: eval_groundness_default_20230915_131943_010944_aggregate_reduce\n",
      "2023-09-15 13:19:52 -0500   16700 execution.flow     INFO     Node aggregate completes.\n",
      "2023-09-15 13:19:52 -0500   16700 execution          INFO     Finish executing aggregation nodes.\n",
      "======= Run Summary =======\n",
      "\n",
      "Run name: \"eval_groundness_default_20230915_131943_010944\"\n",
      "Run status: \"Completed\"\n",
      "Start time: \"2023-09-15 13:19:43.010944\"\n",
      "Duration: \"0:00:09.802669\"\n",
      "Output path: \"C:\\Users\\astalati\\.promptflow\\.runs\\eval_groundness_default_20230915_131943_010944\"\n",
      "\n",
      "name: eval_groundness_default_20230915_131943_010944\n",
      "created_on: '2023-09-15T13:19:43.010944'\n",
      "status: Completed\n",
      "display_name: eval_groundedness_3k_context\n",
      "description: null\n",
      "tags: null\n",
      "properties:\n",
      "  flow_path: D:/repos/chatpdf/Workshop/promptflow/BertChat/eval-groundness\n",
      "  output_path: C:/Users/astalati/.promptflow/.runs/eval_groundness_default_20230915_131943_010944\n",
      "flow_name: eval-groundness\n",
      "data: null\n",
      "output: C:/Users/astalati/.promptflow/.runs/eval_groundness_default_20230915_131943_010944/flow_outputs/output.jsonl\n",
      "run: bertchat_default_20230915_131927_633984\n",
      "\n"
     ]
    }
   ],
   "source": [
    "eval_groundedness_3k_context = pf.run(\n",
    "    flow=eval_groundedness_flow_path,\n",
    "    run=run_3k_context,\n",
    "    column_mapping={\n",
    "        \"question\": \"${run.inputs.question}\",\n",
    "        \"answer\": \"${run.outputs.answer}\",\n",
    "        \"context\": \"${run.outputs.context}\",\n",
    "    },\n",
    "    display_name=\"eval_groundedness_3k_context\",\n",
    ")\n",
    "pf.stream(eval_groundedness_3k_context)\n",
    "\n",
    "print(eval_groundedness_3k_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>inputs.answer</th>\n",
       "      <th>inputs.context</th>\n",
       "      <th>inputs.question</th>\n",
       "      <th>inputs.line_number</th>\n",
       "      <th>outputs.groundedness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The name of the new language representation mo...</td>\n",
       "      <td>[e introduce a new language representa-\\ntion ...</td>\n",
       "      <td>What is the name of the new language represent...</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       inputs.answer  \\\n",
       "0  The name of the new language representation mo...   \n",
       "\n",
       "                                      inputs.context  \\\n",
       "0  [e introduce a new language representa-\\ntion ...   \n",
       "\n",
       "                                     inputs.question  inputs.line_number  \\\n",
       "0  What is the name of the new language represent...                   0   \n",
       "\n",
       "   outputs.groundedness  \n",
       "0                    10  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pf.get_details(eval_groundedness_3k_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The HTML file is generated at 'C:\\\\Users\\\\astalati\\\\AppData\\\\Local\\\\Temp\\\\pf-visualize-detail-lf621pbw.html'.\n",
      "Trying to view the result in a web browser...\n",
      "Successfully visualized from the web browser.\n"
     ]
    }
   ],
   "source": [
    "pf.visualize([eval_groundedness_2k_context, eval_groundedness_3k_context])"
   ]
  }
 ],
 "metadata": {
  "description": "A tutorial of chat-with-pdf flow that allows user ask questions about the content of a PDF file and get answers",
  "kernelspec": {
   "display_name": "prompt-flow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
